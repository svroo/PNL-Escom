{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d9a64e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import os \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.etree.ElementTree import XMLParser\n",
    "from lxml import etree\n",
    "\n",
    "# count_vect = contVectorizer()\n",
    "# x_counts = count_bect.fit_transform(np.array(x)) list of texts, each text is a string\n",
    "# y = np.asrray(y)\n",
    "\n",
    "# tdfif_transformer = tfidftransformer()\n",
    "# x_tfidf = tfidf_transformer.fit_transform(x_counts)\n",
    "\n",
    "# 2.xmlla etiqueta 1-5\n",
    "# 2.review.pos --> texto lemmatizado --> eliminar los tokens que son stopwords y signos de puntuación-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12c9cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_text(path = str(), file = str()):\n",
    "    \"\"\"\n",
    "    Función que regresa el texto del archivo que se le pasa, preferentemente pasar la ruta relativa de donde se encuentra el archivo.\n",
    "    Funciona con los archivos #.review.post del corpus del mismo directorio.\n",
    "    Retorna el texto unicamente.\n",
    "    path = ruta relativa o completa del archivo seleccionado.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(path + file, encoding='latin1', mode = 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    listas = text.split('\\n')\n",
    "    test = []\n",
    "    \n",
    "    for linea in listas:\n",
    "        aux = linea.split(' ')\n",
    "        try:\n",
    "            test.append(aux[1]) \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    cad = ' '.join(test)\n",
    "    return cad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8198604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar(text = str()):\n",
    "    # nltk.download('stopwords') \n",
    "    '''\n",
    "    Funcion para normalizar el texto y eliminar stopwords, así como signos de puntuación, guiones bajos y demás caracteres que no sean texto, retorna la cadena limpia.\n",
    "    text : texto para normalizar\n",
    "    '''\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    lower_string = text.lower()\n",
    "\n",
    "    no_number_string = re.sub(r'\\d+','',lower_string) \n",
    "    no_sub_ = re.sub('[\\_]',' ', no_number_string)\n",
    "    no_punc_string = re.sub(r'[^\\w\\s]','', no_sub_)  \n",
    "    no_wspace_string = no_punc_string.strip() \n",
    "    # no_wspace_string \n",
    "    \n",
    "    lst_string = [no_wspace_string][0].split() \n",
    "    # print(lst_string)\n",
    "    no_stpwords_string=\"\" \n",
    "    for i in lst_string: \n",
    "        if not i in stop_words: \n",
    "            no_stpwords_string += i+' '\n",
    "            \n",
    "    no_stpwords_string = no_stpwords_string[:-1]\n",
    "    \n",
    "    return no_stpwords_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e330a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank (path = str(), file = str(), llave = 'rank'):\n",
    "    \"\"\"\n",
    "    En la función solo se tiene que pasar el path, más el \n",
    "    archivo del cual se quiera obtener el rank, o mejor dicho \n",
    "    la valoración que se obtuvo en la pelicula, el archivo a pasar tiene que \n",
    "    ser en formato .xml para que la función funcione de forma correcta, \n",
    "    retorna el valor entero que se puso en la pelicula.\n",
    "    \n",
    "    path : ruta donde se encuentran los archivos xml\n",
    "    file : nombre del archivo el cual se va a obtener el valor\n",
    "    llave : atributo que se quiere, valor por defecto rank\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(path + file, mode = 'r', encoding= 'latin1') as f:\n",
    "        parser = etree.XMLParser(recover=True)\n",
    "        tree = ET.parse(f, parser=parser)\n",
    "        root = tree.getroot()\n",
    "    \n",
    "        att = root.attrib\n",
    "    \n",
    "    return int(att[llave])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a863725",
   "metadata": {},
   "source": [
    "Obtenemos los archivos con los que vamos a trabajar, en este caso los review.pos y los archivos .xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f84bc837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3878 3886\n"
     ]
    }
   ],
   "source": [
    "path = './corpusCriticasCine/'\n",
    "name_files = os.listdir(path)\n",
    "pos_file = list(filter(lambda x: x.endswith('.review.pos'), name_files))\n",
    "xml_file = list(filter(lambda x: x.endswith('.xml'), name_files))\n",
    "\n",
    "print(len(pos_file), len(xml_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "50773544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = list()\n",
    "# for i in xml_file:\n",
    "#     try:\n",
    "# #         print(i)\n",
    "#         y.append(get_rank(path, i))\n",
    "#     except:\n",
    "#         print(i)\n",
    "#         pass\n",
    "y = [get_rank(path, i) for i in xml_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "fc281514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'Ivan Sainz-Pardo', 'title': 'Batman begins', 'rank': '3', 'maxRank': '5', 'source': 'muchocine'}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68fc3eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [obtener_text(path, pos[i]) for i,j in enumerate(pos_file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "50ea642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clean =[normalizar(text[i]) for i in range(len(text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dcb2eeee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [87]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m count_vect \u001b[38;5;241m=\u001b[39m CountVectorizer()\n\u001b[0;32m      2\u001b[0m x_counts \u001b[38;5;241m=\u001b[39m count_vect\u001b[38;5;241m.\u001b[39mfit_transform(np\u001b[38;5;241m.\u001b[39marray(text_clean)) \u001b[38;5;66;03m#list of texts, each text is a string\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43my\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "x_counts = count_vect.fit_transform(np.array(text_clean)) #list of texts, each text is a string\n",
    "y = np.asarray(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "63963b3f4c440940f0b94a3100916033a226cb4f45979123153792d60aa56d6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
